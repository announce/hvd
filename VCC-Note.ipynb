{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### TODO\n",
    "* Precision-Recall http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
    "* Use Git meta data as feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns\n",
    "0. id\n",
    "1. repository_id\n",
    "2. blamed_commit_id\n",
    "3. type\n",
    "4. sha\n",
    "5. url\n",
    "6. author_email\n",
    "7. author_name\n",
    "8. author_when\n",
    "9. committer_email\n",
    "10. committer_name\n",
    "11. committer_when\n",
    "12. additions\n",
    "13. deletions\n",
    "14. total_changes\n",
    "15. past_changes\n",
    "16. future_changes\n",
    "17. past_different_authors\n",
    "18. future_different_authors\n",
    "19. author_contributions_percent\n",
    "20. message\n",
    "21. patch\n",
    "22. hunk_count\n",
    "23. cve\n",
    "24. files_changed\n",
    "25. patch_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blamed_commit', 714L), ('fixing_commit', 1137L), ('other_commit', 349558L)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(\"dbname=postgres host=localhost port=55432 user=postgres\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT type, COUNT(id) FROM export.commits GROUP BY type\")\n",
    "cur.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import psycopg2\n",
    "import enum\n",
    "\n",
    "class Colum(enum.IntEnum):\n",
    "    id = 1\n",
    "    type = 3\n",
    "    patch = 21\n",
    "    \n",
    "class Data:\n",
    "    def __init__(self, config):\n",
    "        self.cur = psycopg2.connect(config).cursor()\n",
    "    def fetchAll(self, sql):\n",
    "        self.cur.execute(sql)\n",
    "        return np.array(self.cur.fetchall())\n",
    "\n",
    "def tfidf(text):\n",
    "    # @TODO preprocessor: log number\n",
    "    vectorizer = TfidfVectorizer(min_df=1)\n",
    "    vectorized = vectorizer.fit_transform(text)\n",
    "#     print vectorizer.get_feature_names()\n",
    "    return vectorized.toarray()\n",
    "\n",
    "# Fetch original data\n",
    "data = Data(\"dbname=postgres host=localhost port=55432 user=postgres\")\n",
    "vcc = data.fetchAll(\"SELECT * FROM export.commits WHERE type  = 'blamed_commit' ORDER BY RANDOM() LIMIT 50\")\n",
    "ucc = data.fetchAll(\"SELECT * FROM export.commits WHERE type != 'blamed_commit' ORDER BY RANDOM() LIMIT 1000\")\n",
    "\n",
    "# Concat onece and shuffle\n",
    "sample = np.concatenate([vcc, ucc])\n",
    "np.random.shuffle(sample)\n",
    "patches = sample[:, Colum.patch]\n",
    "labels = sample[:, Colum.type]\n",
    "\n",
    "x = tfidf(patches)\n",
    "y = is_vcc = (labels == 'blamed_commit')\n",
    "vcc_paches = patches[is_vcc]\n",
    "ucc_paches = patches[~is_vcc]\n",
    "\n",
    "clf = LinearSVC(C=1.0)\n",
    "scores = cross_validation.cross_val_score(clf, x, y, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Precision-Recall by TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import psycopg2\n",
    "import enum\n",
    "\n",
    "class Colum(enum.IntEnum):\n",
    "    id = 1\n",
    "    type = 3\n",
    "    patch = 21\n",
    "    \n",
    "class Data:\n",
    "    def __init__(self, config):\n",
    "        self.cur = psycopg2.connect(config).cursor()\n",
    "    def fetchAll(self, sql):\n",
    "        self.cur.execute(sql)\n",
    "        return np.array(self.cur.fetchall())\n",
    "\n",
    "def tfidf(text):\n",
    "    vectorizer = TfidfVectorizer(min_df=1)\n",
    "    vectorized = vectorizer.fit_transform(text)\n",
    "    return vectorized.toarray()\n",
    "\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "\n",
    "# Fetch original data\n",
    "data = Data(\"dbname=postgres host=localhost port=55432 user=postgres\")\n",
    "vcc = data.fetchAll(\"SELECT * FROM export.commits WHERE type  = 'blamed_commit' ORDER BY RANDOM() LIMIT 5\")\n",
    "ucc = data.fetchAll(\"SELECT * FROM export.commits WHERE type != 'blamed_commit' ORDER BY RANDOM() LIMIT 100\")\n",
    "\n",
    "# Concat onece and shuffle\n",
    "sample = np.concatenate([vcc, ucc])\n",
    "np.random.shuffle(sample)\n",
    "patches = sample[:, Colum.patch]\n",
    "labels = sample[:, Colum.type]\n",
    "\n",
    "X = tfidf(patches)\n",
    "y = is_vcc = (labels == 'blamed_commit')\n",
    "\n",
    "# Split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=0)\n",
    "\n",
    "# Run classifier\n",
    "classifier = LinearSVC(C=1.0)\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute Precision-Recall and plot curve\n",
    "precision[0], recall[0], _ = precision_recall_curve(y_test, y_score)\n",
    "average_precision[0] = average_precision_score(y_test, y_score)\n",
    "\n",
    "print precision, recall, average_precision\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.clf()\n",
    "plt.plot(recall[0], precision[0], label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision[0]))\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "\n",
    "# # Plot Precision-Recall curve for each class\n",
    "# plt.clf()\n",
    "# plt.plot(recall[0], precision[0], label='Precision-recall curve of class {0} (area = {1:0.2f})'\n",
    "#          ''.format(i, average_precision[0]))\n",
    "\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.title('Extension of Precision-Recall curve to multi-class')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([ 0.05882353,  0.04      ,  0.04081633,  0.04166667,  0.04255319,\n",
      "        0.04347826,  0.04444444,  0.04545455,  0.04651163,  0.02380952,\n",
      "        0.02439024,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ])} {0: array([ 1.        ,  0.66666667,  0.66666667,  0.66666667,  0.66666667,\n",
      "        0.66666667,  0.66666667,  0.66666667,  0.66666667,  0.33333333,\n",
      "        0.33333333,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ])} {0: 0.032255820838450716}\n"
     ]
    }
   ],
   "source": [
    "# Precision-Recall by CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import psycopg2\n",
    "import enum\n",
    "\n",
    "class Colum(enum.IntEnum):\n",
    "    id = 1\n",
    "    type = 3\n",
    "    patch = 21\n",
    "    \n",
    "class Data:\n",
    "    def __init__(self, config):\n",
    "        self.cur = psycopg2.connect(config).cursor()\n",
    "    def fetchAll(self, sql):\n",
    "        self.cur.execute(sql)\n",
    "        return np.array(self.cur.fetchall())\n",
    "\n",
    "def vectorize(text):\n",
    "    vectorizer = CountVectorizer(min_df=1)\n",
    "    vectorized = vectorizer.fit_transform(text)\n",
    "    return vectorized.toarray()\n",
    "\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "\n",
    "# Fetch original data\n",
    "data = Data(\"dbname=postgres host=localhost port=55432 user=postgres\")\n",
    "vcc = data.fetchAll(\"SELECT * FROM export.commits WHERE type  = 'blamed_commit' ORDER BY RANDOM() LIMIT 5\")\n",
    "ucc = data.fetchAll(\"SELECT * FROM export.commits WHERE type != 'blamed_commit' ORDER BY RANDOM() LIMIT 100\")\n",
    "\n",
    "# Concat onece and shuffle\n",
    "sample = np.concatenate([vcc, ucc])\n",
    "np.random.shuffle(sample)\n",
    "patches = sample[:, Colum.patch]\n",
    "labels = sample[:, Colum.type]\n",
    "\n",
    "X = vectorize(patches)\n",
    "y = is_vcc = (labels == 'blamed_commit')\n",
    "\n",
    "# Split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=0)\n",
    "\n",
    "# Run classifier\n",
    "classifier = LinearSVC(C=1.0)\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute Precision-Recall and plot curve\n",
    "precision[0], recall[0], _ = precision_recall_curve(y_test, y_score)\n",
    "average_precision[0] = average_precision_score(y_test, y_score)\n",
    "\n",
    "#print precision, recall, average_precision\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.clf()\n",
    "plt.plot(recall[0], precision[0], label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision[0]))\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([ 0.06      ,  0.04081633,  0.04166667,  0.04255319,  0.04347826,\n",
      "        0.02222222,  0.02272727,  0.02325581,  0.02380952,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ])} {0: array([ 1.        ,  0.66666667,  0.66666667,  0.66666667,  0.66666667,\n",
      "        0.33333333,  0.33333333,  0.33333333,  0.33333333,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ])} {0: 0.031721055571987247}\n"
     ]
    }
   ],
   "source": [
    "# Precision-Recall\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import psycopg2\n",
    "import enum\n",
    "from datetime import datetime\n",
    "from diff_extractor import extract_lines, extract_added_lines, extract_removed_lines\n",
    "\n",
    "import re\n",
    "from unidiff import PatchSet\n",
    "\n",
    "\n",
    "def _normalize(str):\n",
    "    return re.sub(r'[ \\t]+', ' ', str.value.strip())\n",
    "\n",
    "def is_added_or_removed(line):\n",
    "    return line.is_added or line.is_removed\n",
    "    \n",
    "class Colum(enum.IntEnum):\n",
    "    id = 1\n",
    "    type = 3\n",
    "    patch = 21\n",
    "    \n",
    "class Data:\n",
    "    def __init__(self, config):\n",
    "        self.cur = psycopg2.connect(config).cursor()\n",
    "    def fetchAll(self, sql):\n",
    "        self.cur.execute(sql)\n",
    "        return np.array(self.cur.fetchall())\n",
    "\n",
    "def vectorize(text):\n",
    "    vectorizer = CountVectorizer(min_df=1)\n",
    "    vectorized = vectorizer.fit_transform(text)\n",
    "    return vectorized.toarray()\n",
    "\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "\n",
    "# Fetch original data\n",
    "data = Data(\"dbname=postgres host=localhost port=55432 user=postgres\")\n",
    "vcc = data.fetchAll(\"SELECT * FROM export.commits WHERE type  = 'blamed_commit' LIMIT 5\")\n",
    "ucc = data.fetchAll(\"SELECT * FROM export.commits WHERE type != 'blamed_commit' LIMIT 100\")\n",
    "\n",
    "# Concat onece and shuffle\n",
    "sample = np.concatenate([vcc, ucc])\n",
    "np.random.shuffle(sample)\n",
    "patches = sample[:, Colum.patch]\n",
    "labels = sample[:, Colum.type]\n",
    "\n",
    "X = vectorize([\" \".join(extract_lines(patch.decode('utf8', 'ignore').encode('utf8', 'ignore').splitlines(), is_added_or_removed)) for patch in patches])\n",
    "\n",
    "y = is_vcc = (labels == 'blamed_commit')\n",
    "\n",
    "# Split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=0)\n",
    "\n",
    "# Run classifier\n",
    "classifier = LinearSVC(C=1.0)\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute Precision-Recall and plot curve\n",
    "precision[0], recall[0], _ = precision_recall_curve(y_test, y_score)\n",
    "average_precision[0] = average_precision_score(y_test, y_score)\n",
    "\n",
    "print precision, recall, average_precision\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.clf()\n",
    "plt.plot(recall[0], precision[0], label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision[0]))\n",
    "plt.legend(loc=\"lower left\")\n",
    "# plt.show()\n",
    "plt.savefig(\"figure_%s\" % datetime.now().strftime('%s'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO According to VCC-Finder paper, combination with Git metrics improve Precision-Recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "npz = np.load(\"var/vcc_data.npz\")\n",
    "print npz.files\n",
    "# npz['arr_0']\n",
    "npz.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([ 0.03381643,  0.031477  ,  0.0315534 ,  0.03163017,  0.03170732,\n",
      "        0.03178484,  0.03186275,  0.03194103,  0.0320197 ,  0.03209877,\n",
      "        0.03217822,  0.03225806,  0.03233831,  0.03241895,  0.0325    ,\n",
      "        0.03258145,  0.03266332,  0.03274559,  0.03282828,  0.03291139,\n",
      "        0.03299492,  0.03307888,  0.03316327,  0.03324808,  0.03333333,\n",
      "        0.03341902,  0.03350515,  0.03359173,  0.03367876,  0.03376623,\n",
      "        0.03385417,  0.03394256,  0.03403141,  0.03412073,  0.03421053,\n",
      "        0.03430079,  0.03439153,  0.03183024,  0.03191489,  0.032     ,\n",
      "        0.03208556,  0.03217158,  0.03225806,  0.03234501,  0.03243243,\n",
      "        0.03252033,  0.0298913 ,  0.02997275,  0.03005464,  0.03013699,\n",
      "        0.03021978,  0.03030303,  0.03038674,  0.03047091,  0.03055556,\n",
      "        0.02785515,  0.02793296,  0.0280112 ,  0.02808989,  0.02816901,\n",
      "        0.02824859,  0.02549575,  0.02556818,  0.02564103,  0.02571429,\n",
      "        0.02578797,  0.02586207,  0.0259366 ,  0.02601156,  0.02608696,\n",
      "        0.02616279,  0.02623907,  0.02631579,  0.02639296,  0.02647059,\n",
      "        0.02654867,  0.02662722,  0.02670623,  0.02678571,  0.02686567,\n",
      "        0.02694611,  0.02702703,  0.02710843,  0.02719033,  0.02727273,\n",
      "        0.02735562,  0.02743902,  0.02752294,  0.02760736,  0.02769231,\n",
      "        0.02777778,  0.02786378,  0.02795031,  0.02803738,  0.028125  ,\n",
      "        0.02821317,  0.02830189,  0.02839117,  0.02848101,  0.02857143,\n",
      "        0.02866242,  0.02875399,  0.02884615,  0.02893891,  0.02903226,\n",
      "        0.02912621,  0.02922078,  0.02931596,  0.02941176,  0.0295082 ,\n",
      "        0.02960526,  0.02970297,  0.02980132,  0.02990033,  0.03      ,\n",
      "        0.03010033,  0.03020134,  0.03030303,  0.03040541,  0.03050847,\n",
      "        0.03061224,  0.03071672,  0.03082192,  0.03092784,  0.03103448,\n",
      "        0.03114187,  0.03125   ,  0.03135889,  0.03146853,  0.02807018,\n",
      "        0.02816901,  0.02826855,  0.02836879,  0.02846975,  0.02857143,\n",
      "        0.02867384,  0.02877698,  0.02888087,  0.02898551,  0.02909091,\n",
      "        0.02919708,  0.02930403,  0.02941176,  0.0295203 ,  0.02962963,\n",
      "        0.02973978,  0.02985075,  0.02996255,  0.03007519,  0.03018868,\n",
      "        0.03030303,  0.03041825,  0.03053435,  0.03065134,  0.02692308,\n",
      "        0.02702703,  0.02713178,  0.02723735,  0.02734375,  0.02745098,\n",
      "        0.02755906,  0.02766798,  0.02777778,  0.02788845,  0.028     ,\n",
      "        0.02811245,  0.02822581,  0.02834008,  0.02845528,  0.02857143,\n",
      "        0.02868852,  0.02880658,  0.02892562,  0.02904564,  0.02916667,\n",
      "        0.0292887 ,  0.02941176,  0.02953586,  0.02966102,  0.02978723,\n",
      "        0.02991453,  0.03004292,  0.03017241,  0.02597403,  0.02608696,\n",
      "        0.02620087,  0.02631579,  0.02643172,  0.02654867,  0.02666667,\n",
      "        0.02678571,  0.02690583,  0.02702703,  0.02714932,  0.02727273,\n",
      "        0.02739726,  0.02752294,  0.02764977,  0.02777778,  0.02790698,\n",
      "        0.02803738,  0.02816901,  0.02830189,  0.02843602,  0.02857143,\n",
      "        0.02870813,  0.02884615,  0.02898551,  0.02912621,  0.02926829,\n",
      "        0.02941176,  0.02955665,  0.02970297,  0.02985075,  0.03      ,\n",
      "        0.03015075,  0.03030303,  0.03045685,  0.03061224,  0.03076923,\n",
      "        0.03092784,  0.03108808,  0.03125   ,  0.03141361,  0.03157895,\n",
      "        0.03174603,  0.03191489,  0.03208556,  0.03225806,  0.03243243,\n",
      "        0.0326087 ,  0.0273224 ,  0.02747253,  0.02762431,  0.02777778,\n",
      "        0.02793296,  0.02808989,  0.02824859,  0.02840909,  0.02857143,\n",
      "        0.02873563,  0.02890173,  0.02906977,  0.02923977,  0.02941176,\n",
      "        0.0295858 ,  0.0297619 ,  0.02994012,  0.03012048,  0.03030303,\n",
      "        0.0304878 ,  0.03067485,  0.0308642 ,  0.0310559 ,  0.03125   ,\n",
      "        0.03144654,  0.03164557,  0.03184713,  0.03205128,  0.03225806,\n",
      "        0.03246753,  0.03267974,  0.03289474,  0.03311258,  0.03333333,\n",
      "        0.03355705,  0.03378378,  0.03401361,  0.03424658,  0.03448276,\n",
      "        0.03472222,  0.03496503,  0.03521127,  0.03546099,  0.03571429,\n",
      "        0.03597122,  0.03623188,  0.03649635,  0.03676471,  0.03703704,\n",
      "        0.03731343,  0.03759398,  0.03787879,  0.04132231,  0.04166667,\n",
      "        0.04201681,  0.04237288,  0.04273504,  0.04310345,  0.04424779,\n",
      "        0.04464286,  0.04504505,  0.04545455,  0.04587156,  0.0462963 ,\n",
      "        0.04672897,  0.04716981,  0.04761905,  0.04807692,  0.04854369,\n",
      "        0.04901961,  0.04950495,  0.05      ,  0.05050505,  0.05102041,\n",
      "        0.05154639,  0.05208333,  0.05263158,  0.05319149,  0.05376344,\n",
      "        0.05434783,  0.05494505,  0.05555556,  0.05617978,  0.05681818,\n",
      "        0.05747126,  0.05813953,  0.05882353,  0.05952381,  0.06024096,\n",
      "        0.06097561,  0.0617284 ,  0.0625    ,  0.06329114,  0.06410256,\n",
      "        0.06493506,  0.06578947,  0.06666667,  0.06756757,  0.06849315,\n",
      "        0.06944444,  0.07042254,  0.07142857,  0.07246377,  0.07352941,\n",
      "        0.07462687,  0.07575758,  0.07692308,  0.078125  ,  0.07936508,\n",
      "        0.08064516,  0.08196721,  0.08333333,  0.08474576,  0.0862069 ,\n",
      "        0.0877193 ,  0.08928571,  0.09090909,  0.09259259,  0.09433962,\n",
      "        0.09615385,  0.09803922,  0.1       ,  0.10204082,  0.10416667,\n",
      "        0.10638298,  0.10869565,  0.11111111,  0.11363636,  0.11627907,\n",
      "        0.11904762,  0.12195122,  0.125     ,  0.12820513,  0.13157895,\n",
      "        0.13513514,  0.13888889,  0.14285714,  0.14705882,  0.15151515,\n",
      "        0.125     ,  0.12903226,  0.13333333,  0.13793103,  0.14285714,\n",
      "        0.14814815,  0.15384615,  0.16      ,  0.16666667,  0.17391304,\n",
      "        0.18181818,  0.19047619,  0.2       ,  0.21052632,  0.22222222,\n",
      "        0.23529412,  0.25      ,  0.26666667,  0.28571429,  0.30769231,\n",
      "        0.33333333,  0.36363636,  0.4       ,  0.33333333,  0.375     ,\n",
      "        0.28571429,  0.33333333,  0.4       ,  0.5       ,  0.66666667,\n",
      "        0.5       ,  1.        ,  1.        ])} {0: array([ 1.        ,  0.92857143,  0.92857143,  0.92857143,  0.92857143,\n",
      "        0.92857143,  0.92857143,  0.92857143,  0.92857143,  0.92857143,\n",
      "        0.92857143,  0.92857143,  0.92857143,  0.92857143,  0.92857143,\n",
      "        0.92857143,  0.92857143,  0.92857143,  0.92857143,  0.92857143,\n",
      "        0.92857143,  0.92857143,  0.92857143,  0.92857143,  0.92857143,\n",
      "        0.92857143,  0.92857143,  0.92857143,  0.92857143,  0.92857143,\n",
      "        0.92857143,  0.92857143,  0.92857143,  0.92857143,  0.92857143,\n",
      "        0.92857143,  0.92857143,  0.85714286,  0.85714286,  0.85714286,\n",
      "        0.85714286,  0.85714286,  0.85714286,  0.85714286,  0.85714286,\n",
      "        0.85714286,  0.78571429,  0.78571429,  0.78571429,  0.78571429,\n",
      "        0.78571429,  0.78571429,  0.78571429,  0.78571429,  0.78571429,\n",
      "        0.71428571,  0.71428571,  0.71428571,  0.71428571,  0.71428571,\n",
      "        0.71428571,  0.64285714,  0.64285714,  0.64285714,  0.64285714,\n",
      "        0.64285714,  0.64285714,  0.64285714,  0.64285714,  0.64285714,\n",
      "        0.64285714,  0.64285714,  0.64285714,  0.64285714,  0.64285714,\n",
      "        0.64285714,  0.64285714,  0.64285714,  0.64285714,  0.64285714,\n",
      "        0.64285714,  0.64285714,  0.64285714,  0.64285714,  0.64285714,\n",
      "        0.64285714,  0.64285714,  0.64285714,  0.64285714,  0.64285714,\n",
      "        0.64285714,  0.64285714,  0.64285714,  0.64285714,  0.64285714,\n",
      "        0.64285714,  0.64285714,  0.64285714,  0.64285714,  0.64285714,\n",
      "        0.64285714,  0.64285714,  0.64285714,  0.64285714,  0.64285714,\n",
      "        0.64285714,  0.64285714,  0.64285714,  0.64285714,  0.64285714,\n",
      "        0.64285714,  0.64285714,  0.64285714,  0.64285714,  0.64285714,\n",
      "        0.64285714,  0.64285714,  0.64285714,  0.64285714,  0.64285714,\n",
      "        0.64285714,  0.64285714,  0.64285714,  0.64285714,  0.64285714,\n",
      "        0.64285714,  0.64285714,  0.64285714,  0.64285714,  0.57142857,\n",
      "        0.57142857,  0.57142857,  0.57142857,  0.57142857,  0.57142857,\n",
      "        0.57142857,  0.57142857,  0.57142857,  0.57142857,  0.57142857,\n",
      "        0.57142857,  0.57142857,  0.57142857,  0.57142857,  0.57142857,\n",
      "        0.57142857,  0.57142857,  0.57142857,  0.57142857,  0.57142857,\n",
      "        0.57142857,  0.57142857,  0.57142857,  0.57142857,  0.5       ,\n",
      "        0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
      "        0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
      "        0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
      "        0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
      "        0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
      "        0.5       ,  0.5       ,  0.5       ,  0.42857143,  0.42857143,\n",
      "        0.42857143,  0.42857143,  0.42857143,  0.42857143,  0.42857143,\n",
      "        0.42857143,  0.42857143,  0.42857143,  0.42857143,  0.42857143,\n",
      "        0.42857143,  0.42857143,  0.42857143,  0.42857143,  0.42857143,\n",
      "        0.42857143,  0.42857143,  0.42857143,  0.42857143,  0.42857143,\n",
      "        0.42857143,  0.42857143,  0.42857143,  0.42857143,  0.42857143,\n",
      "        0.42857143,  0.42857143,  0.42857143,  0.42857143,  0.42857143,\n",
      "        0.42857143,  0.42857143,  0.42857143,  0.42857143,  0.42857143,\n",
      "        0.42857143,  0.42857143,  0.42857143,  0.42857143,  0.42857143,\n",
      "        0.42857143,  0.42857143,  0.42857143,  0.42857143,  0.42857143,\n",
      "        0.42857143,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.35714286,  0.35714286,  0.35714286,  0.35714286,  0.35714286,\n",
      "        0.28571429,  0.28571429,  0.28571429,  0.28571429,  0.28571429,\n",
      "        0.28571429,  0.28571429,  0.28571429,  0.28571429,  0.28571429,\n",
      "        0.28571429,  0.28571429,  0.28571429,  0.28571429,  0.28571429,\n",
      "        0.28571429,  0.28571429,  0.28571429,  0.28571429,  0.28571429,\n",
      "        0.28571429,  0.28571429,  0.28571429,  0.21428571,  0.21428571,\n",
      "        0.14285714,  0.14285714,  0.14285714,  0.14285714,  0.14285714,\n",
      "        0.07142857,  0.07142857,  0.        ])} {0: 0.19201792765190365}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import enum\n",
    "from datetime import datetime\n",
    "from diff_extractor import extract_lines, extract_added_lines, extract_removed_lines\n",
    "\n",
    "class Colum(enum.IntEnum):\n",
    "    id = 1\n",
    "    type = 3\n",
    "    patch = 21\n",
    "    \n",
    "def fetch(filename, key = None):\n",
    "    npz = np.load(filename)\n",
    "    key = npz.files[0] if key is None else key\n",
    "    data = npz[key]\n",
    "    npz.close()\n",
    "    return data\n",
    "\n",
    "def vectorize(text):\n",
    "    vectorizer = CountVectorizer(min_df=1)\n",
    "    vectorized = vectorizer.fit_transform(text)\n",
    "    return vectorized.toarray()\n",
    "\n",
    "data = fetch('var/vcc_sample_40x800.npz')\n",
    "\n",
    "patches = data[:, Colum.patch]\n",
    "labels = data[:, Colum.type]\n",
    "\n",
    "# Note: Be sure that unicode(patch, 'utf-8')\n",
    "X = vectorize([\" \".join(extract_lines(patch.splitlines())) for patch in patches])\n",
    "y = is_vcc = (labels == 'blamed_commit')\n",
    "\n",
    "# Split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=0)\n",
    "\n",
    "# Run classifier\n",
    "classifier = LinearSVC(C=1.0)\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute Precision-Recall and plot curve\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "precision[0], recall[0], _ = precision_recall_curve(y_test, y_score)\n",
    "average_precision[0] = average_precision_score(y_test, y_score)\n",
    "\n",
    "print precision, recall, average_precision\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.clf()\n",
    "plt.plot(recall[0], precision[0], label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision[0]))\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "plt.savefig(\"figure_%s\" % datetime.now().strftime('%s'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascii\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print sys.getdefaultencoding()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
